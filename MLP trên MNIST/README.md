# Thá»±c nghiá»‡m 2: MLP trÃªn MNIST

## ðŸ“– MÃ´ táº£

Thá»±c nghiá»‡m nÃ y so sÃ¡nh hiá»‡u suáº¥t cá»§a thuáº­t toÃ¡n Adam vÃ  Adam+SAM trÃªn mÃ´ hÃ¬nh Multi-Layer Perceptron vá»›i dataset MNIST.

## ðŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh

```
Input (784)
    â†“
Linear(784, 256) -> ReLU -> Dropout(0.2)
    â†“
Linear(256, 128) -> ReLU -> Dropout(0.2)
    â†“
Linear(128, 10) -> Output (10 classes)
```

**Tá»•ng sá»‘ tham sá»‘**: ~235,146

## âš™ï¸ Cáº¥u hÃ¬nh

- **Dataset**: MNIST (60,000 train, 10,000 test)
- **Input size**: 28x28 = 784
- **Hidden layers**: [256, 128]
- **Output classes**: 10 (digits 0-9)
- **Batch size**: 128
- **Epochs**: 50
- **Learning rate**: 0.001
- **Dropout**: 0.2
- **Optimizer**: Adam / Adam+SAM (rho=0.05)

## ðŸš€ Cháº¡y thá»±c nghiá»‡m

```bash
python mlp_mnist.py
```

## ðŸ“Š Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c

### Adam
- Training Accuracy: ~98-99%
- Test Accuracy: ~97.5-98%

### Adam + SAM
- Training Accuracy: ~98.5-99%
- Test Accuracy: ~98-98.5%
- **Cáº£i thiá»‡n**: +0.5-1% test accuracy

## ðŸ“ˆ Biá»ƒu Ä‘á»“

Sau khi cháº¡y xong, file `mlp_comparison.png` sáº½ Ä‘Æ°á»£c táº¡o ra vá»›i 4 biá»ƒu Ä‘á»“:
1. Training Loss
2. Test Loss
3. Training Accuracy
4. Test Accuracy

## ðŸ” Quan sÃ¡t

1. **Deep Network**: MLP sÃ¢u hÆ¡n Logistic Regression, SAM giÃºp trÃ¡nh overfitting tá»‘t hÆ¡n
2. **Dropout Effect**: Káº¿t há»£p Dropout vá»›i SAM cho káº¿t quáº£ tá»•ng quÃ¡t hÃ³a tá»‘t nháº¥t
3. **Training Stability**: SAM cÃ³ training curve mÆ°á»£t vÃ  á»•n Ä‘á»‹nh hÆ¡n
4. **Convergence Speed**: Adam há»™i tá»¥ nhanh hÆ¡n, nhÆ°ng SAM Ä‘áº¡t test accuracy cao hÆ¡n

## ðŸ’¾ Output

- `mlp_comparison.png`: Biá»ƒu Ä‘á»“ so sÃ¡nh
- Console output: Chi tiáº¿t tá»«ng epoch vÃ  káº¿t quáº£ cuá»‘i cÃ¹ng
- `./data/MNIST`: ThÆ° má»¥c chá»©a dataset (tá»± Ä‘á»™ng táº£i)

## ðŸŽ“ Ã nghÄ©a

MLP lÃ  mÃ´ hÃ¬nh phá»• biáº¿n vÃ  dá»… bá»‹ overfitting hÆ¡n Logistic Regression. Thá»±c nghiá»‡m nÃ y cho tháº¥y SAM Ä‘áº·c biá»‡t hiá»‡u quáº£ vá»›i máº¡ng neural sÃ¢u hÆ¡n, giÃºp cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a.

## ðŸ”§ TÃ¹y chá»‰nh

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i cÃ¡c tham sá»‘ trong code:
- `hidden_dims = [256, 128]` -> Thay Ä‘á»•i sá»‘ neurons
- `dropout = 0.2` -> Äiá»u chá»‰nh dropout rate
- `epochs = 50` -> TÄƒng/giáº£m sá»‘ epochs
- `rho = 0.05` -> Thay Ä‘á»•i SAM radius
