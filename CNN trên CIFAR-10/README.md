# Thá»±c nghiá»‡m 3: CNN nhá» trÃªn CIFAR-10

## ğŸ“– MÃ´ táº£

Thá»±c nghiá»‡m nÃ y so sÃ¡nh hiá»‡u suáº¥t cá»§a thuáº­t toÃ¡n Adam vÃ  Adam+SAM trÃªn mÃ´ hÃ¬nh Convolutional Neural Network vá»›i dataset CIFAR-10.

## ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh

```
Input (3x32x32)
    â†“
Conv2d(3, 32, 3x3) -> BatchNorm -> ReLU -> MaxPool(2x2)    [32x16x16]
    â†“
Conv2d(32, 64, 3x3) -> BatchNorm -> ReLU -> MaxPool(2x2) -> Dropout2d(0.25)    [64x8x8]
    â†“
Conv2d(64, 128, 3x3) -> BatchNorm -> ReLU -> MaxPool(2x2) -> Dropout2d(0.25)   [128x4x4]
    â†“
Flatten [2048]
    â†“
Linear(2048, 256) -> ReLU -> Dropout(0.5)
    â†“
Linear(256, 10) -> Output (10 classes)
```

**Tá»•ng sá»‘ tham sá»‘**: ~588,042

## âš™ï¸ Cáº¥u hÃ¬nh

- **Dataset**: CIFAR-10 (50,000 train, 10,000 test)
- **Input size**: 32x32x3 (color images)
- **Output classes**: 10 (plane, car, bird, cat, deer, dog, frog, horse, ship, truck)
- **Batch size**: 128
- **Epochs**: 100
- **Learning rate**: 0.001
- **Data Augmentation**: 
  - Random Crop (32x32 with padding=4)
  - Random Horizontal Flip
- **Normalization**: Mean=(0.4914, 0.4822, 0.4465), Std=(0.2023, 0.1994, 0.2010)
- **Optimizer**: Adam / Adam+SAM (rho=0.05)

## ğŸš€ Cháº¡y thá»±c nghiá»‡m

```bash
python cnn_cifar10.py
```

âš ï¸ **LÆ°u Ã½**: Thá»±c nghiá»‡m nÃ y máº¥t nhiá»u thá»i gian hÆ¡n (100 epochs)

## ğŸ“Š Káº¿t quáº£ Ä‘áº¡t Ä‘Æ°á»£c

### Adam
- Training Accuracy: ~85-90%
- Test Accuracy: ~75-78%
- Best Test Accuracy: ~76-78%

### Adam + SAM
- Training Accuracy: ~82-87%
- Test Accuracy: ~77-80%
- Best Test Accuracy: ~78-81%
- Training time: ~20-30 phÃºt (GPU) / ~4-6 giá» (CPU)
- **Cáº£i thiá»‡n**: +2-3% test accuracy

## ğŸ“ˆ Biá»ƒu Ä‘á»“

Sau khi cháº¡y xong, file `cnn_cifar10_comparison.png` sáº½ Ä‘Æ°á»£c táº¡o ra vá»›i 4 biá»ƒu Ä‘á»“:
1. Training Loss
2. Test Loss
3. Training Accuracy
4. Test Accuracy

## ğŸ” Quan sÃ¡t

1. **Complex Dataset**: CIFAR-10 khÃ³ hÆ¡n MNIST, SAM cho tháº¥y lá»£i Ã­ch rÃµ rá»‡t hÆ¡n
2. **Overfitting**: Adam thÆ°á»ng overfit hÆ¡n (train acc cao nhÆ°ng test acc tháº¥p hÆ¡n)
3. **SAM Effect**: SAM giáº£m overfitting Ä‘Ã¡ng ká»ƒ, train acc tháº¥p hÆ¡n nhÆ°ng test acc cao hÆ¡n
4. **Data Augmentation**: Káº¿t há»£p data augmentation vá»›i SAM cho káº¿t quáº£ tá»‘t nháº¥t
5. **Best Accuracy**: SAM thÆ°á»ng Ä‘áº¡t best test accuracy cao hÆ¡n 2-3%

## ğŸ’¾ Output

- `cnn_cifar10_comparison.png`: Biá»ƒu Ä‘á»“ so sÃ¡nh
- Console output: Chi tiáº¿t tá»«ng 10 epoch vÃ  káº¿t quáº£ cuá»‘i cÃ¹ng
- `./data/cifar-10-batches-py`: ThÆ° má»¥c chá»©a dataset (tá»± Ä‘á»™ng táº£i, ~170MB)

## ğŸ“ Ã nghÄ©a

CIFAR-10 lÃ  benchmark quan trá»ng trong computer vision. Thá»±c nghiá»‡m nÃ y cho tháº¥y:
- SAM Ä‘áº·c biá»‡t hiá»‡u quáº£ vá»›i CNN vÃ  dá»¯ liá»‡u phá»©c táº¡p
- Trade-off giá»¯a training accuracy vÃ  test accuracy
- Flat minima (do SAM tÃ¬m Ä‘Æ°á»£c) tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n sharp minima

## ğŸ”§ TÃ¹y chá»‰nh

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i cÃ¡c tham sá»‘ trong code:
- `epochs = 100` -> TÄƒng lÃªn 150-200 Ä‘á»ƒ káº¿t quáº£ tá»‘t hÆ¡n
- `learning_rate = 0.001` -> Thá»­ learning rate decay
- `rho = 0.05` -> Thá»­ rho = 0.1 hoáº·c 0.02
- ThÃªm conv layers Ä‘á»ƒ mÃ´ hÃ¬nh máº¡nh hÆ¡n

## ğŸ’¡ Tips

1. **GPU recommended**: CNN huáº¥n luyá»‡n ráº¥t cháº­m trÃªn CPU
2. **Patience**: 100 epochs máº¥t thá»i gian, cÃ³ thá»ƒ giáº£m xuá»‘ng 50 Ä‘á»ƒ test nhanh
3. **Memory**: Cáº§n ~2-3GB RAM/VRAM
4. **num_workers**: ÄÃ£ set num_workers=2 cho DataLoader, cÃ³ thá»ƒ tÄƒng náº¿u CPU máº¡nh

## ğŸ† Benchmark

State-of-the-art trÃªn CIFAR-10:
- Simple CNN: ~75-80%
- ResNet: ~90-95%
- Vision Transformer: ~95-98%

MÃ´ hÃ¬nh nÃ y Ä‘áº¡t ~78-80% vá»›i Adam+SAM lÃ  káº¿t quáº£ tá»‘t cho small CNN!
