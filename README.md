# So sÃ¡nh Thuáº­t toÃ¡n Tá»‘i Æ°u: Adam vs Adam+SAM

Dá»± Ã¡n nÃ y thá»±c hiá»‡n 3 thá»±c nghiá»‡m Ä‘á»ƒ so sÃ¡nh hiá»‡u suáº¥t cá»§a thuáº­t toÃ¡n Adam vá»›i Adam káº¿t há»£p Sharpness-Aware Minimization (SAM).

## ğŸ“‹ Má»¥c lá»¥c

1. [Thá»±c nghiá»‡m 1: Logistic Regression trÃªn MNIST](#thá»±c-nghiá»‡m-1)
2. [Thá»±c nghiá»‡m 2: MLP trÃªn MNIST](#thá»±c-nghiá»‡m-2)
3. [Thá»±c nghiá»‡m 3: CNN nhá» trÃªn CIFAR-10](#thá»±c-nghiá»‡m-3)

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8 trá»Ÿ lÃªn
- GPU (khuyáº¿n nghá»‹, khÃ´ng báº¯t buá»™c)

### CÃ i Ä‘áº·t thÆ° viá»‡n

```bash
pip install -r requirements.txt
```

Hoáº·c cÃ i Ä‘áº·t thá»§ cÃ´ng:

```bash
pip install torch torchvision matplotlib numpy
```

### CÃ i Ä‘áº·t PyTorch vá»›i CUDA (náº¿u cÃ³ GPU)

Truy cáº­p https://pytorch.org/ Ä‘á»ƒ cÃ i Ä‘áº·t phiÃªn báº£n phÃ¹ há»£p vá»›i há»‡ thá»‘ng cá»§a báº¡n.

VÃ­ dá»¥ cho Windows vá»›i CUDA 11.8:
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“Š Thá»±c nghiá»‡m 1: Logistic Regression trÃªn MNIST

### MÃ´ táº£
- **MÃ´ hÃ¬nh**: Logistic Regression (Linear layer Ä‘Æ¡n giáº£n)
- **Dataset**: MNIST (28x28 grayscale images, 10 classes)
- **Sá»‘ tham sá»‘**: ~7,850
- **Epochs**: 50
- **Batch size**: 128
- **Learning rate**: 0.001

### Cháº¡y thá»±c nghiá»‡m

```bash
cd "Logistic Regression trÃªn MNIST"
python logistic_regression_mnist.py
```

### Káº¿t quáº£ mong Ä‘á»£i
- Adam: ~92-93% test accuracy
- Adam+SAM: ~93-94% test accuracy (cáº£i thiá»‡n ~1%)

## ğŸ“Š Thá»±c nghiá»‡m 2: MLP trÃªn MNIST

### MÃ´ táº£
- **MÃ´ hÃ¬nh**: Multi-Layer Perceptron (2 hidden layers: 256, 128)
- **Dataset**: MNIST (28x28 grayscale images, 10 classes)
- **Sá»‘ tham sá»‘**: ~235,146
- **Epochs**: 50
- **Batch size**: 128
- **Learning rate**: 0.001
- **Dropout**: 0.2

### Cháº¡y thá»±c nghiá»‡m

```bash
cd "MLP trÃªn MNIST"
python mlp_mnist.py
```

### Káº¿t quáº£ mong Ä‘á»£i
- Adam: ~97-98% test accuracy
- Adam+SAM: ~98-99% test accuracy (cáº£i thiá»‡n ~0.5-1%)

## ğŸ“Š Thá»±c nghiá»‡m 3: CNN nhá» trÃªn CIFAR-10

### MÃ´ táº£
- **MÃ´ hÃ¬nh**: Small CNN (3 conv layers + 2 FC layers)
- **Dataset**: CIFAR-10 (32x32 color images, 10 classes)
- **Sá»‘ tham sá»‘**: ~588,042
- **Epochs**: 100
- **Batch size**: 128
- **Learning rate**: 0.001
- **Data augmentation**: Random crop, horizontal flip

### Cháº¡y thá»±c nghiá»‡m

```bash
cd "CNN trÃªn CIFAR-10"
python cnn_cifar10.py
```

### Káº¿t quáº£ mong Ä‘á»£i
- Adam: ~75-78% test accuracy
- Adam+SAM: ~77-80% test accuracy (cáº£i thiá»‡n ~2-3%)

## ğŸ“ˆ Káº¿t quáº£ vÃ  Biá»ƒu Ä‘á»“

Má»—i thá»±c nghiá»‡m sáº½ tá»± Ä‘á»™ng:
1. Táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u
2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i Adam
3. Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i Adam+SAM
4. Táº¡o biá»ƒu Ä‘á»“ so sÃ¡nh (lÆ°u dÆ°á»›i dáº¡ng PNG)
5. In káº¿t quáº£ chi tiáº¿t ra console

### CÃ¡c biá»ƒu Ä‘á»“ Ä‘Æ°á»£c táº¡o ra:
- `logistic_regression_comparison.png` - Thá»±c nghiá»‡m 1
- `mlp_comparison.png` - Thá»±c nghiá»‡m 2
- `cnn_cifar10_comparison.png` - Thá»±c nghiá»‡m 3

Má»—i biá»ƒu Ä‘á»“ bao gá»“m 4 subplot:
- Training Loss
- Test Loss
- Training Accuracy
- Test Accuracy

## ğŸ”¬ Vá» SAM (Sharpness-Aware Minimization)

SAM lÃ  má»™t ká»¹ thuáº­t tá»‘i Æ°u giÃºp cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a cá»§a mÃ´ hÃ¬nh báº±ng cÃ¡ch:
- TÃ¬m cÃ¡c vÃ¹ng "pháº³ng" trong khÃ´ng gian tham sá»‘ (flat minima)
- Thá»±c hiá»‡n 2 láº§n forward-backward pass má»—i iteration
- Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p test mÃ  khÃ´ng overfitting

**Trade-off**: Thá»i gian huáº¥n luyá»‡n tÄƒng gáº¥p ~2 láº§n so vá»›i Adam thÃ´ng thÆ°á»ng.

## ğŸ“ Tham sá»‘ SAM

- `rho`: 0.05 (default) - BÃ¡n kÃ­nh neighborhood Ä‘á»ƒ tÃ¬m adversarial perturbation
- `adaptive`: False - CÃ³ sá»­ dá»¥ng adaptive SAM hay khÃ´ng

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i cÃ¡c tham sá»‘ nÃ y trong code Ä‘á»ƒ thá»­ nghiá»‡m.

## ğŸ¯ Má»¥c tiÃªu So sÃ¡nh

1. **Accuracy**: Adam+SAM thÆ°á»ng Ä‘áº¡t accuracy cao hÆ¡n
2. **Generalization**: Adam+SAM cÃ³ test loss tháº¥p hÆ¡n, giáº£m overfitting
3. **Training time**: Adam+SAM cháº­m hÆ¡n ~2x do double forward-backward
4. **Stability**: Adam+SAM thÆ°á»ng cÃ³ Ä‘Æ°á»ng training á»•n Ä‘á»‹nh hÆ¡n

## ğŸ’¡ Tips

1. **GPU**: Náº¿u cÃ³ GPU, thá»i gian cháº¡y sáº½ nhanh hÆ¡n Ä‘Ã¡ng ká»ƒ
2. **Data**: Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng táº£i xuá»‘ng vÃ o thÆ° má»¥c `./data`
3. **Reproducibility**: ÄÃ£ set seed=42 cho táº¥t cáº£ cÃ¡c thá»±c nghiá»‡m
4. **Memory**: CNN trÃªn CIFAR-10 cáº§n nhiá»u RAM/VRAM nháº¥t

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Sharpness-Aware Minimization Paper](https://arxiv.org/abs/2010.01412)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)

## ğŸ› Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p

### Lá»—i CUDA out of memory
```bash
# Giáº£m batch_size trong code (dÃ²ng batch_size = 128 -> 64)
```

### Lá»—i táº£i dataset
```bash
# Thá»­ táº£i thá»§ cÃ´ng hoáº·c kiá»ƒm tra káº¿t ná»‘i internet
# Dataset sáº½ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c ./data
```

### Lá»—i matplotlib
```bash
pip install --upgrade matplotlib
```

## ğŸ“§ LiÃªn há»‡

Náº¿u cÃ³ váº¥n Ä‘á» khi cháº¡y code, hÃ£y kiá»ƒm tra:
1. ÄÃ£ cÃ i Ä‘áº·t Ä‘Ãºng thÆ° viá»‡n chÆ°a
2. Python version >= 3.8
3. CÃ³ Ä‘á»§ disk space cho dataset chÆ°a (MNIST ~50MB, CIFAR-10 ~170MB)

---

**ChÃºc báº¡n thá»±c nghiá»‡m thÃ nh cÃ´ng! ğŸ‰**
