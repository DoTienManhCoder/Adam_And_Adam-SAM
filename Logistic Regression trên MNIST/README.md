# Thá»±c nghiá»‡m 1: Logistic Regression trÃªn MNIST

## ğŸ“– MÃ´ táº£

Thá»±c nghiá»‡m nÃ y so sÃ¡nh hiá»‡u suáº¥t cá»§a thuáº­t toÃ¡n Adam vÃ  Adam+SAM trÃªn mÃ´ hÃ¬nh Logistic Regression Ä‘Æ¡n giáº£n vá»›i dataset MNIST.

## ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh

```
Input (784) -> Linear(784, 10) -> Output (10 classes)
```

**Tá»•ng sá»‘ tham sá»‘**: ~7,850

## âš™ï¸ Cáº¥u hÃ¬nh

- **Dataset**: MNIST (60,000 train, 10,000 test)
- **Input size**: 28x28 = 784
- **Output classes**: 10 (digits 0-9)
- **Batch size**: 128
- **Epochs**: 50
- **Learning rate**: 0.001
- **Optimizer**: Adam / Adam+SAM (rho=0.05)

## ğŸš€ Cháº¡y thá»±c nghiá»‡m

```bash
python logistic_regression_mnist.py
```

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

### Adam
- Training Accuracy: ~93-94%
- Test Accuracy: ~92-93%
- Training time: ~2-3 phÃºt (CPU) / ~30s (GPU)

### Adam + SAM
- Training Accuracy: ~94-95%
- Test Accuracy: ~93-94%
- Training time: ~4-6 phÃºt (CPU) / ~1 phÃºt (GPU)
- **Cáº£i thiá»‡n**: +1-1.5% test accuracy

## ğŸ“ˆ Biá»ƒu Ä‘á»“

Sau khi cháº¡y xong, file `logistic_regression_comparison.png` sáº½ Ä‘Æ°á»£c táº¡o ra vá»›i 4 biá»ƒu Ä‘á»“:
1. Training Loss
2. Test Loss
3. Training Accuracy
4. Test Accuracy

## ğŸ” Quan sÃ¡t

1. **Convergence**: Adam+SAM há»™i tá»¥ cháº­m hÆ¡n nhÆ°ng á»•n Ä‘á»‹nh hÆ¡n
2. **Generalization**: Test accuracy cá»§a SAM cao hÆ¡n, cho tháº¥y kháº£ nÄƒng tá»•ng quÃ¡t tá»‘t hÆ¡n
3. **Overfitting**: SAM giáº£m overfitting so vá»›i Adam
4. **Trade-off**: Thá»i gian training tÄƒng ~2x

## ğŸ’¾ Output

- `logistic_regression_comparison.png`: Biá»ƒu Ä‘á»“ so sÃ¡nh
- Console output: Chi tiáº¿t tá»«ng epoch vÃ  káº¿t quáº£ cuá»‘i cÃ¹ng
- `./data/MNIST`: ThÆ° má»¥c chá»©a dataset (tá»± Ä‘á»™ng táº£i)

## ğŸ“ Ã nghÄ©a

Thá»±c nghiá»‡m nÃ y cho tháº¥y ngay cáº£ vá»›i mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n nhÆ° Logistic Regression, SAM váº«n cÃ³ thá»ƒ cáº£i thiá»‡n kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a. Äiá»u nÃ y Ä‘áº·c biá»‡t há»¯u Ã­ch khi lÃ m viá»‡c vá»›i dá»¯ liá»‡u háº¡n cháº¿ hoáº·c cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao.
